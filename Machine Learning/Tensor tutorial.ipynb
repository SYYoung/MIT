{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2],\n",
       "        [3, 4]]),\n",
       " tensor([[1, 2],\n",
       "         [3, 4]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2],[3,4]])\n",
    "x_tensor = torch.from_numpy(x)\n",
    "x, x_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on : cpu\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3,4)\n",
    "print(f\"Device tensor is stored on : {x.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.9292, 1.7509, 1.0860, 1.4008],\n",
      "        [1.2181, 1.7912, 1.2149, 1.2868],\n",
      "        [1.7526, 1.2620, 1.3840, 1.4162]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2.9292, 2.7509, 2.0860, 2.4008],\n",
       "        [2.2181, 2.7912, 2.2149, 2.2868],\n",
       "        [2.7526, 2.2620, 2.3840, 2.4162]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x)\n",
    "x = x + 1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /Users/kilingcheung/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aefb8fc9c2914c9199d27b65da680cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "data = torch.rand(1,3,64,64)\n",
    "labels = torch.rand(1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (prediction - labels).sum()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([2.,3.], requires_grad=True)\n",
    "b = torch.tensor([6.,4.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 3*a**3 - b**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-12.,  65.], grad_fn=<SubBackward0>),\n",
       " tensor([2., 3.], requires_grad=True),\n",
       " tensor([6., 4.], requires_grad=True))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q, a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_grad = torch.tensor([1.,1.])\n",
    "Q.backward(gradient=external_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([36., 81.]), tensor([-12.,  -8.]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad, b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36., 81.], grad_fn=<MulBackward0>) tensor([-12.,  -8.], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(9*a**2, -2*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4762, -0.2049, -0.3061,  0.4685, -0.4765,  1.2930, -0.1513,  0.2410,\n",
      "        -0.3915, -0.8265])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.randn(10)\n",
    "print(target)\n",
    "target = target.view(1,-1)\n",
    "target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function view:\n",
      "\n",
      "view(...) method of torch.Tensor instance\n",
      "    view(*shape) -> Tensor\n",
      "    \n",
      "    Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "    different :attr:`shape`.\n",
      "    \n",
      "    The returned tensor shares the same data and must have the same number\n",
      "    of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "    view size must be compatible with its original size and stride, i.e., each new\n",
      "    view dimension must either be a subspace of an original dimension, or only span\n",
      "    across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "    contiguity-like condition that :math:`\\forall i = d, \\dots, d+k-1`,\n",
      "    \n",
      "    .. math::\n",
      "    \n",
      "      \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "    \n",
      "    Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`\n",
      "    without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a\n",
      "    :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which\n",
      "    returns a view if the shapes are compatible, and copies (equivalent to calling\n",
      "    :meth:`contiguous`) otherwise.\n",
      "    \n",
      "    Args:\n",
      "        shape (torch.Size or int...): the desired size\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> x = torch.randn(4, 4)\n",
      "        >>> x.size()\n",
      "        torch.Size([4, 4])\n",
      "        >>> y = x.view(16)\n",
      "        >>> y.size()\n",
      "        torch.Size([16])\n",
      "        >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "        >>> z.size()\n",
      "        torch.Size([2, 8])\n",
      "    \n",
      "        >>> a = torch.randn(1, 2, 3, 4)\n",
      "        >>> a.size()\n",
      "        torch.Size([1, 2, 3, 4])\n",
      "        >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "        >>> b.size()\n",
      "        torch.Size([1, 3, 2, 4])\n",
      "        >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "        >>> c.size()\n",
      "        torch.Size([1, 3, 2, 4])\n",
      "        >>> torch.equal(b, c)\n",
      "        False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(target.view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
